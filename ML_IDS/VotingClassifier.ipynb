{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal     724\n",
      "anomaly    337\n",
      "Name: class, dtype: int64\n",
      "(1061, 9)\n",
      "(1061,)\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gb', GradientBoostingClassifier()), ('dtc', DecisionTreeClassifier())]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9404388714733543\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 80  18]\n",
      " [  1 220]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.99      0.82      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.96      0.91      0.93       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gb', GradientBoostingClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs'))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9341692789968652\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 77  21]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.79      0.88        98\n",
      "      normal       0.91      1.00      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.96      0.89      0.92       319\n",
      "weighted avg       0.94      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gb', GradientBoostingClassifier()), ('gnb', GaussianNB())]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9341692789968652\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 77  21]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.79      0.88        98\n",
      "      normal       0.91      1.00      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.96      0.89      0.92       319\n",
      "weighted avg       0.94      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gb', GradientBoostingClassifier()), ('svm', SVC(kernel='linear', probability=True))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9341692789968652\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 77  21]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.79      0.88        98\n",
      "      normal       0.91      1.00      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.96      0.89      0.92       319\n",
      "weighted avg       0.94      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gb', GradientBoostingClassifier()), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9341692789968652\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 77  21]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.79      0.88        98\n",
      "      normal       0.91      1.00      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.96      0.89      0.92       319\n",
      "weighted avg       0.94      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gb', GradientBoostingClassifier()), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9341692789968652\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 77  21]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.79      0.88        98\n",
      "      normal       0.91      1.00      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.96      0.89      0.92       319\n",
      "weighted avg       0.94      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('dtc', DecisionTreeClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs'))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9310344827586207\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 79  19]\n",
      " [  3 218]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.96      0.81      0.88        98\n",
      "      normal       0.92      0.99      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.94      0.90      0.91       319\n",
      "weighted avg       0.93      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('dtc', DecisionTreeClassifier()), ('gnb', GaussianNB())]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9373040752351097\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 79  19]\n",
      " [  1 220]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.99      0.81      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.95      0.90      0.92       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('dtc', DecisionTreeClassifier()), ('svm', SVC(kernel='linear', probability=True))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9373040752351097\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 79  19]\n",
      " [  1 220]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.99      0.81      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.95      0.90      0.92       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('dtc', DecisionTreeClassifier()), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9341692789968652\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  1 220]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.99      0.80      0.88        98\n",
      "      normal       0.92      1.00      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.95      0.90      0.92       319\n",
      "weighted avg       0.94      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('dtc', DecisionTreeClassifier()), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9310344827586207\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  2 219]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.97      0.80      0.88        98\n",
      "      normal       0.92      0.99      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.95      0.89      0.91       319\n",
      "weighted avg       0.93      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('gnb', GaussianNB())]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7836990595611285\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 29  69]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.30      0.46        98\n",
      "      normal       0.76      1.00      0.86       221\n",
      "\n",
      "    accuracy                           0.78       319\n",
      "   macro avg       0.88      0.65      0.66       319\n",
      "weighted avg       0.84      0.78      0.74       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('svm', SVC(kernel='linear', probability=True))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.774294670846395\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 26  72]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.27      0.42        98\n",
      "      normal       0.75      1.00      0.86       221\n",
      "\n",
      "    accuracy                           0.77       319\n",
      "   macro avg       0.88      0.63      0.64       319\n",
      "weighted avg       0.83      0.77      0.72       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 33  65]\n",
      " [  2 219]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.94      0.34      0.50        98\n",
      "      normal       0.77      0.99      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.86      0.66      0.68       319\n",
      "weighted avg       0.82      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gnb', GaussianNB()), ('svm', SVC(kernel='linear', probability=True))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7366771159874608\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 14  84]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.14      0.25        98\n",
      "      normal       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.74       319\n",
      "   macro avg       0.86      0.57      0.55       319\n",
      "weighted avg       0.81      0.74      0.66       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gnb', GaussianNB()), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7366771159874608\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 14  84]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.14      0.25        98\n",
      "      normal       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.74       319\n",
      "   macro avg       0.86      0.57      0.55       319\n",
      "weighted avg       0.81      0.74      0.66       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('gnb', GaussianNB()), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('svm', SVC(kernel='linear', probability=True)), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7366771159874608\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 14  84]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.14      0.25        98\n",
      "      normal       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.74       319\n",
      "   macro avg       0.86      0.57      0.55       319\n",
      "weighted avg       0.81      0.74      0.66       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('svm', SVC(kernel='linear', probability=True)), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('rf', RandomForestClassifier(random_state=1)), ('lr', LogisticRegression(n_jobs=-1, random_state=0)), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('dtc', DecisionTreeClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs'))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9373040752351097\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.80      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.96      0.90      0.92       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('dtc', DecisionTreeClassifier()), ('gnb', GaussianNB())]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9373040752351097\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.80      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.96      0.90      0.92       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('dtc', DecisionTreeClassifier()), ('svm', SVC(kernel='linear', probability=True))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9373040752351097\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.80      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.96      0.90      0.92       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('dtc', DecisionTreeClassifier()), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9373040752351097\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.80      0.89        98\n",
      "      normal       0.92      1.00      0.96       221\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.96      0.90      0.92       319\n",
      "weighted avg       0.94      0.94      0.94       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('dtc', DecisionTreeClassifier()), ('knn', KNeighborsClassifier(n_jobs=-1))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9310344827586207\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 78  20]\n",
      " [  2 219]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.97      0.80      0.88        98\n",
      "      normal       0.92      0.99      0.95       221\n",
      "\n",
      "    accuracy                           0.93       319\n",
      "   macro avg       0.95      0.89      0.91       319\n",
      "weighted avg       0.93      0.93      0.93       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('gnb', GaussianNB())]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7836990595611285\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 29  69]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.30      0.46        98\n",
      "      normal       0.76      1.00      0.86       221\n",
      "\n",
      "    accuracy                           0.78       319\n",
      "   macro avg       0.88      0.65      0.66       319\n",
      "weighted avg       0.84      0.78      0.74       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('svm', SVC(kernel='linear', probability=True))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7836990595611285\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 29  69]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.30      0.46        98\n",
      "      normal       0.76      1.00      0.86       221\n",
      "\n",
      "    accuracy                           0.78       319\n",
      "   macro avg       0.88      0.65      0.66       319\n",
      "weighted avg       0.84      0.78      0.74       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7962382445141066\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 33  65]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.34      0.50        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.80       319\n",
      "   macro avg       0.89      0.67      0.69       319\n",
      "weighted avg       0.84      0.80      0.76       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('knn', KNeighborsClassifier(n_jobs=-1))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7774294670846394\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 32  66]\n",
      " [  5 216]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.86      0.33      0.47        98\n",
      "      normal       0.77      0.98      0.86       221\n",
      "\n",
      "    accuracy                           0.78       319\n",
      "   macro avg       0.82      0.65      0.67       319\n",
      "weighted avg       0.80      0.78      0.74       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('gnb', GaussianNB()), ('svm', SVC(kernel='linear', probability=True))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7366771159874608\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 14  84]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.14      0.25        98\n",
      "      normal       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.74       319\n",
      "   macro avg       0.86      0.57      0.55       319\n",
      "weighted avg       0.81      0.74      0.66       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('gnb', GaussianNB()), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7366771159874608\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 14  84]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.14      0.25        98\n",
      "      normal       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.74       319\n",
      "   macro avg       0.86      0.57      0.55       319\n",
      "weighted avg       0.81      0.74      0.66       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('gnb', GaussianNB()), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('svm', SVC(kernel='linear', probability=True)), ('lr', LogisticRegression(n_jobs=-1, random_state=0))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7366771159874608\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 14  84]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.14      0.25        98\n",
      "      normal       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.74       319\n",
      "   macro avg       0.86      0.57      0.55       319\n",
      "weighted avg       0.81      0.74      0.66       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('svm', SVC(kernel='linear', probability=True)), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('gb', GradientBoostingClassifier()), ('lr', LogisticRegression(n_jobs=-1, random_state=0)), ('knn', KNeighborsClassifier(n_jobs=-1))]\n",
      "\n",
      "============================== Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7899686520376176\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 31  67]\n",
      " [  0 221]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      0.32      0.48        98\n",
      "      normal       0.77      1.00      0.87       221\n",
      "\n",
      "    accuracy                           0.79       319\n",
      "   macro avg       0.88      0.66      0.67       319\n",
      "weighted avg       0.84      0.79      0.75       319\n",
      "\n",
      "\n",
      "[('dtc', DecisionTreeClassifier()), ('mlp', MLPClassifier(max_iter=5000, solver='lbfgs')), ('gnb', GaussianNB())]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-43556f33a5ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0meclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     71\u001b[0m                              % (len(self.weights), len(self.estimators)))\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m     74\u001b[0m                 delayed(_fit_single_estimator)(\n\u001b[0;32m     75\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \"\"\"\n\u001b[1;32m-> 1027\u001b[1;33m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0m\u001b[0;32m   1028\u001b[0m                                             hasattr(self, \"classes_\")))\n\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0m\u001b[0;32m    376\u001b[0m                             intercept_grads, layer_units)\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[0;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_grad_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    615\u001b[0m                                   **options)\n\u001b[0;32m    616\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0m\u001b[0;32m    178\u001b[0m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0;32m    179\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;31m# Forward propagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# Get loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# For the hidden layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# For the last layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_base.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[0;32m   2095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2096\u001b[0m     \"\"\"\n\u001b[1;32m-> 2097\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             um.maximum, a, min, out=out, casting=casting, **kwargs)\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         return _clip_dep_invoke_with_casting(\n\u001b[0m\u001b[0;32m    141\u001b[0m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[1;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# try to deal with broken casting rules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_UFuncOutputCastingError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# Numpy 1.17.0, 2019-02-24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/sebaa/OneDrive/Studies/Thesis_RISE_2021/Thesis_ML_impl/labelled.csv\")\n",
    "\n",
    "# Distribution of normal and anomaly traffic in train data\n",
    "print(train['class'].value_counts())\n",
    "\n",
    "#features = train.columns.tolist()\n",
    "#features.remove('timestamp'), features.remove('class'), features.remove('attack_type')\n",
    "\n",
    "#PREPROCESSING\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "# turn the result back to a dataframe\n",
    "train_x = pd.DataFrame(sc_train, columns = cols)\n",
    "train_y = train['class']\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.70, random_state=1)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#RandomForest classifier\n",
    "clf1= RandomForestClassifier(random_state=1)\n",
    "#Gradient Boost\n",
    "clf2 = GradientBoostingClassifier()\n",
    "#ETC\n",
    "clf3 = ExtraTreesClassifier()\n",
    "#DTC\n",
    "clf4 = DecisionTreeClassifier()\n",
    "#ANN\n",
    "clf5 = MLPClassifier(solver='lbfgs', max_iter = 5000)\n",
    "#Naive Bayes\n",
    "clf6 = GaussianNB()\n",
    "#SVM\n",
    "clf7 = svm.SVC(kernel='linear', probability=True)\n",
    "#LR\n",
    "clf8 = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "#KNN\n",
    "clf9 = KNeighborsClassifier(n_jobs=-1)\n",
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "clf10 = LDA()\n",
    "labels = [('rf', clf1), ('gb', clf2), ('dtc', clf4), ('mlp',clf5), ('gnb', clf6), ('svm', clf7), ('lr', clf8), \n",
    "          ('knn', clf9)]\n",
    "for i in list(itertools.combinations(labels, 3)):\n",
    "    print(list(i))\n",
    "\n",
    "    eclf = VotingClassifier(estimators=list(i), voting='hard')\n",
    "    eclf.fit(X_train, Y_train)\n",
    "    accuracy = metrics.accuracy_score(Y_test, eclf.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, eclf.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, eclf.predict(X_test)) \n",
    "    print()\n",
    "    print('============================== Model Test Results ==============================')\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
